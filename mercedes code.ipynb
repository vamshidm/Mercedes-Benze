{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import randint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 1600)\n",
    "pd.set_option('display.max_rows', 1600)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 378)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mercedes_df = pd.read_csv(\"Mercedes.csv\")\n",
    "mercedes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x21f2b4379c8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(mercedes_df['y'], mercedes_df['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mercedes_df=mercedes_df[mercedes_df['y']<150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_df=pd.DataFrame({\n",
    "    'cloumn_name':mercedes_df.columns,\n",
    "    'missing_count':mercedes_df.isnull().sum(),\n",
    "    'missing_value_%':mercedes_df.isnull().sum()/mercedes_df.shape[0]*100\n",
    "})\n",
    "#missing_values_df.sort_values(by='missing_value_%',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=mercedes_df.iloc[:,1]\n",
    "y=np.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4194, 376)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = mercedes_df.iloc[:, 2:]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4194, 363)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_drop=[]\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].nunique()==X.shape[0] or X[col].nunique()==1:\n",
    "        cols_drop.append(col)\n",
    "        X.drop(columns=col, inplace=True)\n",
    "print(len(cols_drop))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3355 entries, 2745 to 863\n",
      "Columns: 363 entries, X0 to X385\n",
      "dtypes: int64(355), object(8)\n",
      "memory usage: 9.3+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoderExt(object):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
    "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
    "        \"\"\"\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        # self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "    def fit(self, data_list):\n",
    "        \"\"\"\n",
    "        This will fit the encoder for all the unique values and introduce unknown value\n",
    "        :param data_list: A list of string\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
    "        self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_list):\n",
    "        \"\"\"\n",
    "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
    "        :param data_list:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        new_data_list = list(data_list)\n",
    "        for unique_item in np.unique(data_list):\n",
    "            if unique_item not in self.label_encoder.classes_:\n",
    "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
    "\n",
    "        return self.label_encoder.transform(new_data_list)\n",
    "    \n",
    "le=LabelEncoderExt()\n",
    "\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].dtype=='object':\n",
    "        le.fit(X_train[col])\n",
    "        X_train[col]=le.transform(X_train[col])\n",
    "        X_test[col]=le.transform(X_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "pca=PCA()\n",
    "X_train_pca_df=pd.DataFrame(pca.fit_transform(X_train))\n",
    "\n",
    "#pca.explained_variance_ratio_#by default it is in decreasing order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Explained veriance ratio')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel(\"Number of Principal Components\")\n",
    "plt.ylabel(\"Explained veriance ratio\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1 = PCA(n_components=45)\n",
    "X_train_pca_df = pd.DataFrame(pca1.fit_transform(X_train), columns=list(range(0,45)))\n",
    "X_test_pca_df =  pd.DataFrame(pca1.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.544289</td>\n",
       "      <td>-0.824992</td>\n",
       "      <td>2.843841</td>\n",
       "      <td>-2.544883</td>\n",
       "      <td>1.313584</td>\n",
       "      <td>-4.510989</td>\n",
       "      <td>1.497924</td>\n",
       "      <td>-1.848113</td>\n",
       "      <td>2.373873</td>\n",
       "      <td>-0.227971</td>\n",
       "      <td>-1.036275</td>\n",
       "      <td>-0.539819</td>\n",
       "      <td>-0.364791</td>\n",
       "      <td>-0.873234</td>\n",
       "      <td>1.028271</td>\n",
       "      <td>0.284250</td>\n",
       "      <td>0.087535</td>\n",
       "      <td>0.058733</td>\n",
       "      <td>0.664031</td>\n",
       "      <td>-1.168386</td>\n",
       "      <td>-0.508829</td>\n",
       "      <td>0.590414</td>\n",
       "      <td>-0.746548</td>\n",
       "      <td>-0.419586</td>\n",
       "      <td>0.270346</td>\n",
       "      <td>0.159327</td>\n",
       "      <td>-0.097584</td>\n",
       "      <td>0.131015</td>\n",
       "      <td>0.327636</td>\n",
       "      <td>0.172926</td>\n",
       "      <td>0.269879</td>\n",
       "      <td>0.547658</td>\n",
       "      <td>-0.143616</td>\n",
       "      <td>-0.077515</td>\n",
       "      <td>-0.212644</td>\n",
       "      <td>-0.019858</td>\n",
       "      <td>-0.049473</td>\n",
       "      <td>-0.184009</td>\n",
       "      <td>-0.226855</td>\n",
       "      <td>-0.180927</td>\n",
       "      <td>-0.068320</td>\n",
       "      <td>0.135709</td>\n",
       "      <td>0.032409</td>\n",
       "      <td>-0.055209</td>\n",
       "      <td>0.234126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-9.959137</td>\n",
       "      <td>2.312521</td>\n",
       "      <td>-5.690243</td>\n",
       "      <td>16.131003</td>\n",
       "      <td>-4.432750</td>\n",
       "      <td>-2.355228</td>\n",
       "      <td>-0.752267</td>\n",
       "      <td>-2.927850</td>\n",
       "      <td>-0.955589</td>\n",
       "      <td>0.079541</td>\n",
       "      <td>-0.124050</td>\n",
       "      <td>0.271745</td>\n",
       "      <td>-0.429917</td>\n",
       "      <td>-0.377628</td>\n",
       "      <td>0.436771</td>\n",
       "      <td>0.157324</td>\n",
       "      <td>-0.940005</td>\n",
       "      <td>0.660553</td>\n",
       "      <td>0.522868</td>\n",
       "      <td>-0.390994</td>\n",
       "      <td>0.716241</td>\n",
       "      <td>-0.990446</td>\n",
       "      <td>0.508297</td>\n",
       "      <td>-0.129431</td>\n",
       "      <td>0.259507</td>\n",
       "      <td>-0.515533</td>\n",
       "      <td>-0.065383</td>\n",
       "      <td>-0.266527</td>\n",
       "      <td>-0.046385</td>\n",
       "      <td>-0.257940</td>\n",
       "      <td>0.103083</td>\n",
       "      <td>-0.291695</td>\n",
       "      <td>-0.314269</td>\n",
       "      <td>-0.067524</td>\n",
       "      <td>0.405480</td>\n",
       "      <td>0.074450</td>\n",
       "      <td>0.368322</td>\n",
       "      <td>-0.033768</td>\n",
       "      <td>-0.304901</td>\n",
       "      <td>-0.022537</td>\n",
       "      <td>-0.112632</td>\n",
       "      <td>0.130355</td>\n",
       "      <td>0.065607</td>\n",
       "      <td>0.137011</td>\n",
       "      <td>0.116226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.638594</td>\n",
       "      <td>-1.888735</td>\n",
       "      <td>6.522407</td>\n",
       "      <td>-14.471979</td>\n",
       "      <td>-7.173325</td>\n",
       "      <td>-2.281573</td>\n",
       "      <td>0.788575</td>\n",
       "      <td>-1.923893</td>\n",
       "      <td>1.651098</td>\n",
       "      <td>-0.561466</td>\n",
       "      <td>-0.534814</td>\n",
       "      <td>0.374972</td>\n",
       "      <td>-1.352883</td>\n",
       "      <td>0.309155</td>\n",
       "      <td>-0.471496</td>\n",
       "      <td>0.084396</td>\n",
       "      <td>-0.212429</td>\n",
       "      <td>-0.024047</td>\n",
       "      <td>-0.304478</td>\n",
       "      <td>0.294221</td>\n",
       "      <td>1.087248</td>\n",
       "      <td>-0.627109</td>\n",
       "      <td>0.396787</td>\n",
       "      <td>0.138117</td>\n",
       "      <td>-0.195273</td>\n",
       "      <td>-0.538636</td>\n",
       "      <td>0.738193</td>\n",
       "      <td>0.301050</td>\n",
       "      <td>-0.493639</td>\n",
       "      <td>-0.883594</td>\n",
       "      <td>0.137393</td>\n",
       "      <td>-0.190730</td>\n",
       "      <td>0.123261</td>\n",
       "      <td>0.202526</td>\n",
       "      <td>0.150256</td>\n",
       "      <td>-0.350714</td>\n",
       "      <td>-0.225407</td>\n",
       "      <td>0.392292</td>\n",
       "      <td>0.138637</td>\n",
       "      <td>-0.177242</td>\n",
       "      <td>-0.191377</td>\n",
       "      <td>0.230836</td>\n",
       "      <td>0.023830</td>\n",
       "      <td>-0.165797</td>\n",
       "      <td>-0.295334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>28.545711</td>\n",
       "      <td>14.048909</td>\n",
       "      <td>-5.890521</td>\n",
       "      <td>8.691848</td>\n",
       "      <td>-2.105240</td>\n",
       "      <td>-2.068995</td>\n",
       "      <td>1.128292</td>\n",
       "      <td>-0.324627</td>\n",
       "      <td>-0.761758</td>\n",
       "      <td>-0.789632</td>\n",
       "      <td>1.633666</td>\n",
       "      <td>-0.576225</td>\n",
       "      <td>1.355754</td>\n",
       "      <td>-0.549369</td>\n",
       "      <td>1.015327</td>\n",
       "      <td>2.146630</td>\n",
       "      <td>-0.432287</td>\n",
       "      <td>-0.589077</td>\n",
       "      <td>-0.127214</td>\n",
       "      <td>0.449546</td>\n",
       "      <td>0.198616</td>\n",
       "      <td>-0.624624</td>\n",
       "      <td>-0.060750</td>\n",
       "      <td>0.319459</td>\n",
       "      <td>0.765583</td>\n",
       "      <td>-0.513115</td>\n",
       "      <td>0.045952</td>\n",
       "      <td>0.232231</td>\n",
       "      <td>-0.244286</td>\n",
       "      <td>0.224951</td>\n",
       "      <td>-0.061547</td>\n",
       "      <td>0.478726</td>\n",
       "      <td>0.181395</td>\n",
       "      <td>-0.377737</td>\n",
       "      <td>-0.490816</td>\n",
       "      <td>-0.062465</td>\n",
       "      <td>-0.098364</td>\n",
       "      <td>0.088359</td>\n",
       "      <td>0.445133</td>\n",
       "      <td>0.150082</td>\n",
       "      <td>0.124207</td>\n",
       "      <td>-0.211369</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>0.244105</td>\n",
       "      <td>-0.585212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-2.263481</td>\n",
       "      <td>-8.139869</td>\n",
       "      <td>11.287388</td>\n",
       "      <td>4.394998</td>\n",
       "      <td>-12.202797</td>\n",
       "      <td>0.357330</td>\n",
       "      <td>-2.664678</td>\n",
       "      <td>0.129632</td>\n",
       "      <td>-0.518654</td>\n",
       "      <td>-0.660245</td>\n",
       "      <td>0.054001</td>\n",
       "      <td>-0.402660</td>\n",
       "      <td>0.600628</td>\n",
       "      <td>-0.142739</td>\n",
       "      <td>1.218801</td>\n",
       "      <td>0.477337</td>\n",
       "      <td>-0.552997</td>\n",
       "      <td>0.146693</td>\n",
       "      <td>0.300694</td>\n",
       "      <td>0.316413</td>\n",
       "      <td>-0.651149</td>\n",
       "      <td>-1.395147</td>\n",
       "      <td>-0.994150</td>\n",
       "      <td>0.009017</td>\n",
       "      <td>-0.860938</td>\n",
       "      <td>-0.113742</td>\n",
       "      <td>0.545029</td>\n",
       "      <td>-0.164758</td>\n",
       "      <td>-0.668395</td>\n",
       "      <td>-0.389105</td>\n",
       "      <td>0.251451</td>\n",
       "      <td>0.914531</td>\n",
       "      <td>0.176540</td>\n",
       "      <td>-0.149310</td>\n",
       "      <td>-0.149043</td>\n",
       "      <td>-0.313318</td>\n",
       "      <td>0.048973</td>\n",
       "      <td>-0.584387</td>\n",
       "      <td>0.145278</td>\n",
       "      <td>-0.228382</td>\n",
       "      <td>-0.059748</td>\n",
       "      <td>0.237914</td>\n",
       "      <td>-0.277846</td>\n",
       "      <td>0.502227</td>\n",
       "      <td>0.132296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>-14.219149</td>\n",
       "      <td>-6.974966</td>\n",
       "      <td>4.092569</td>\n",
       "      <td>-10.268049</td>\n",
       "      <td>-7.130547</td>\n",
       "      <td>0.910125</td>\n",
       "      <td>-2.759280</td>\n",
       "      <td>1.676623</td>\n",
       "      <td>-1.895374</td>\n",
       "      <td>1.155819</td>\n",
       "      <td>1.379139</td>\n",
       "      <td>-0.230293</td>\n",
       "      <td>-1.285764</td>\n",
       "      <td>-1.476814</td>\n",
       "      <td>1.656293</td>\n",
       "      <td>0.186880</td>\n",
       "      <td>0.310852</td>\n",
       "      <td>0.439531</td>\n",
       "      <td>0.061626</td>\n",
       "      <td>-0.920937</td>\n",
       "      <td>0.296203</td>\n",
       "      <td>0.566254</td>\n",
       "      <td>-0.369008</td>\n",
       "      <td>-0.128690</td>\n",
       "      <td>-0.068601</td>\n",
       "      <td>-0.224132</td>\n",
       "      <td>0.179661</td>\n",
       "      <td>-0.321636</td>\n",
       "      <td>0.291466</td>\n",
       "      <td>-0.189636</td>\n",
       "      <td>-0.446249</td>\n",
       "      <td>0.074973</td>\n",
       "      <td>0.111538</td>\n",
       "      <td>0.166842</td>\n",
       "      <td>0.192033</td>\n",
       "      <td>-0.452788</td>\n",
       "      <td>-0.068857</td>\n",
       "      <td>0.205273</td>\n",
       "      <td>0.272273</td>\n",
       "      <td>-0.102809</td>\n",
       "      <td>-0.067893</td>\n",
       "      <td>-0.284417</td>\n",
       "      <td>0.143581</td>\n",
       "      <td>-0.110138</td>\n",
       "      <td>-0.052485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3351</td>\n",
       "      <td>0.552702</td>\n",
       "      <td>16.452711</td>\n",
       "      <td>0.200888</td>\n",
       "      <td>9.764205</td>\n",
       "      <td>-10.341630</td>\n",
       "      <td>-4.134721</td>\n",
       "      <td>1.136563</td>\n",
       "      <td>0.721318</td>\n",
       "      <td>-1.382319</td>\n",
       "      <td>-1.017499</td>\n",
       "      <td>0.900494</td>\n",
       "      <td>-0.738191</td>\n",
       "      <td>0.557064</td>\n",
       "      <td>0.835164</td>\n",
       "      <td>-0.345780</td>\n",
       "      <td>-0.541781</td>\n",
       "      <td>0.097288</td>\n",
       "      <td>0.850518</td>\n",
       "      <td>0.717570</td>\n",
       "      <td>0.664378</td>\n",
       "      <td>0.485552</td>\n",
       "      <td>0.493027</td>\n",
       "      <td>-0.655081</td>\n",
       "      <td>-1.136077</td>\n",
       "      <td>-0.988839</td>\n",
       "      <td>0.346736</td>\n",
       "      <td>-0.365619</td>\n",
       "      <td>0.324004</td>\n",
       "      <td>-0.859652</td>\n",
       "      <td>-0.112508</td>\n",
       "      <td>0.557931</td>\n",
       "      <td>-0.157967</td>\n",
       "      <td>0.404897</td>\n",
       "      <td>0.333191</td>\n",
       "      <td>0.189529</td>\n",
       "      <td>-0.287762</td>\n",
       "      <td>-0.177926</td>\n",
       "      <td>-0.305335</td>\n",
       "      <td>-0.089031</td>\n",
       "      <td>0.619654</td>\n",
       "      <td>0.231737</td>\n",
       "      <td>-0.036520</td>\n",
       "      <td>0.325149</td>\n",
       "      <td>0.044162</td>\n",
       "      <td>-0.080211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3352</td>\n",
       "      <td>-9.193261</td>\n",
       "      <td>1.516230</td>\n",
       "      <td>13.556272</td>\n",
       "      <td>9.754312</td>\n",
       "      <td>-2.245289</td>\n",
       "      <td>-1.547189</td>\n",
       "      <td>1.431038</td>\n",
       "      <td>-1.824192</td>\n",
       "      <td>-1.683108</td>\n",
       "      <td>1.508862</td>\n",
       "      <td>-0.261287</td>\n",
       "      <td>0.912091</td>\n",
       "      <td>-1.048905</td>\n",
       "      <td>0.129091</td>\n",
       "      <td>-0.224614</td>\n",
       "      <td>-0.201466</td>\n",
       "      <td>-0.798110</td>\n",
       "      <td>0.618364</td>\n",
       "      <td>1.719355</td>\n",
       "      <td>1.389720</td>\n",
       "      <td>-0.082800</td>\n",
       "      <td>-0.321606</td>\n",
       "      <td>0.940902</td>\n",
       "      <td>0.510068</td>\n",
       "      <td>-0.628191</td>\n",
       "      <td>-0.093034</td>\n",
       "      <td>-0.783109</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>0.697227</td>\n",
       "      <td>0.389809</td>\n",
       "      <td>0.465626</td>\n",
       "      <td>0.231340</td>\n",
       "      <td>-0.343397</td>\n",
       "      <td>0.137666</td>\n",
       "      <td>-0.473930</td>\n",
       "      <td>0.552502</td>\n",
       "      <td>0.092304</td>\n",
       "      <td>0.438345</td>\n",
       "      <td>0.249907</td>\n",
       "      <td>-0.725016</td>\n",
       "      <td>-0.161702</td>\n",
       "      <td>0.115188</td>\n",
       "      <td>-0.631952</td>\n",
       "      <td>-0.416700</td>\n",
       "      <td>-0.249932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3353</td>\n",
       "      <td>-14.002240</td>\n",
       "      <td>11.481141</td>\n",
       "      <td>10.546388</td>\n",
       "      <td>-5.651545</td>\n",
       "      <td>-2.751973</td>\n",
       "      <td>-1.785202</td>\n",
       "      <td>-1.588163</td>\n",
       "      <td>-0.468043</td>\n",
       "      <td>-0.513397</td>\n",
       "      <td>-0.286634</td>\n",
       "      <td>-0.127733</td>\n",
       "      <td>0.417867</td>\n",
       "      <td>0.319218</td>\n",
       "      <td>-1.601648</td>\n",
       "      <td>-0.355809</td>\n",
       "      <td>0.949766</td>\n",
       "      <td>1.321265</td>\n",
       "      <td>-0.466270</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>0.215675</td>\n",
       "      <td>-0.126002</td>\n",
       "      <td>-0.929815</td>\n",
       "      <td>1.170759</td>\n",
       "      <td>0.055459</td>\n",
       "      <td>-0.362601</td>\n",
       "      <td>0.269442</td>\n",
       "      <td>0.277268</td>\n",
       "      <td>0.371096</td>\n",
       "      <td>-1.050715</td>\n",
       "      <td>1.144143</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.202115</td>\n",
       "      <td>-0.213449</td>\n",
       "      <td>-0.289618</td>\n",
       "      <td>-0.108093</td>\n",
       "      <td>0.024667</td>\n",
       "      <td>-0.187419</td>\n",
       "      <td>-0.319528</td>\n",
       "      <td>0.043697</td>\n",
       "      <td>0.594970</td>\n",
       "      <td>0.128063</td>\n",
       "      <td>-0.160156</td>\n",
       "      <td>-0.144663</td>\n",
       "      <td>-0.203815</td>\n",
       "      <td>0.079255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3354</td>\n",
       "      <td>-8.593283</td>\n",
       "      <td>17.335740</td>\n",
       "      <td>-10.253766</td>\n",
       "      <td>-3.075604</td>\n",
       "      <td>3.936105</td>\n",
       "      <td>-0.428898</td>\n",
       "      <td>-0.303729</td>\n",
       "      <td>1.079620</td>\n",
       "      <td>-1.451576</td>\n",
       "      <td>0.401473</td>\n",
       "      <td>2.079771</td>\n",
       "      <td>-0.448212</td>\n",
       "      <td>0.331677</td>\n",
       "      <td>-0.368223</td>\n",
       "      <td>-0.230561</td>\n",
       "      <td>-0.612622</td>\n",
       "      <td>0.269717</td>\n",
       "      <td>0.421747</td>\n",
       "      <td>1.235381</td>\n",
       "      <td>0.532070</td>\n",
       "      <td>-0.594915</td>\n",
       "      <td>0.423322</td>\n",
       "      <td>0.252245</td>\n",
       "      <td>-0.955708</td>\n",
       "      <td>0.562276</td>\n",
       "      <td>-0.073609</td>\n",
       "      <td>0.096507</td>\n",
       "      <td>-0.340302</td>\n",
       "      <td>0.637882</td>\n",
       "      <td>0.380862</td>\n",
       "      <td>0.196633</td>\n",
       "      <td>-0.345499</td>\n",
       "      <td>0.524958</td>\n",
       "      <td>0.384078</td>\n",
       "      <td>-0.034621</td>\n",
       "      <td>0.054517</td>\n",
       "      <td>0.097114</td>\n",
       "      <td>0.014107</td>\n",
       "      <td>-0.082066</td>\n",
       "      <td>-0.060045</td>\n",
       "      <td>0.313545</td>\n",
       "      <td>0.049815</td>\n",
       "      <td>0.094020</td>\n",
       "      <td>0.100053</td>\n",
       "      <td>0.032122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3355 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2          3          4         5   \\\n",
       "0     -1.544289  -0.824992   2.843841  -2.544883   1.313584 -4.510989   \n",
       "1     -9.959137   2.312521  -5.690243  16.131003  -4.432750 -2.355228   \n",
       "2      2.638594  -1.888735   6.522407 -14.471979  -7.173325 -2.281573   \n",
       "3     28.545711  14.048909  -5.890521   8.691848  -2.105240 -2.068995   \n",
       "4     -2.263481  -8.139869  11.287388   4.394998 -12.202797  0.357330   \n",
       "...         ...        ...        ...        ...        ...       ...   \n",
       "3350 -14.219149  -6.974966   4.092569 -10.268049  -7.130547  0.910125   \n",
       "3351   0.552702  16.452711   0.200888   9.764205 -10.341630 -4.134721   \n",
       "3352  -9.193261   1.516230  13.556272   9.754312  -2.245289 -1.547189   \n",
       "3353 -14.002240  11.481141  10.546388  -5.651545  -2.751973 -1.785202   \n",
       "3354  -8.593283  17.335740 -10.253766  -3.075604   3.936105 -0.428898   \n",
       "\n",
       "            6         7         8         9         10        11        12  \\\n",
       "0     1.497924 -1.848113  2.373873 -0.227971 -1.036275 -0.539819 -0.364791   \n",
       "1    -0.752267 -2.927850 -0.955589  0.079541 -0.124050  0.271745 -0.429917   \n",
       "2     0.788575 -1.923893  1.651098 -0.561466 -0.534814  0.374972 -1.352883   \n",
       "3     1.128292 -0.324627 -0.761758 -0.789632  1.633666 -0.576225  1.355754   \n",
       "4    -2.664678  0.129632 -0.518654 -0.660245  0.054001 -0.402660  0.600628   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3350 -2.759280  1.676623 -1.895374  1.155819  1.379139 -0.230293 -1.285764   \n",
       "3351  1.136563  0.721318 -1.382319 -1.017499  0.900494 -0.738191  0.557064   \n",
       "3352  1.431038 -1.824192 -1.683108  1.508862 -0.261287  0.912091 -1.048905   \n",
       "3353 -1.588163 -0.468043 -0.513397 -0.286634 -0.127733  0.417867  0.319218   \n",
       "3354 -0.303729  1.079620 -1.451576  0.401473  2.079771 -0.448212  0.331677   \n",
       "\n",
       "            13        14        15        16        17        18        19  \\\n",
       "0    -0.873234  1.028271  0.284250  0.087535  0.058733  0.664031 -1.168386   \n",
       "1    -0.377628  0.436771  0.157324 -0.940005  0.660553  0.522868 -0.390994   \n",
       "2     0.309155 -0.471496  0.084396 -0.212429 -0.024047 -0.304478  0.294221   \n",
       "3    -0.549369  1.015327  2.146630 -0.432287 -0.589077 -0.127214  0.449546   \n",
       "4    -0.142739  1.218801  0.477337 -0.552997  0.146693  0.300694  0.316413   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3350 -1.476814  1.656293  0.186880  0.310852  0.439531  0.061626 -0.920937   \n",
       "3351  0.835164 -0.345780 -0.541781  0.097288  0.850518  0.717570  0.664378   \n",
       "3352  0.129091 -0.224614 -0.201466 -0.798110  0.618364  1.719355  1.389720   \n",
       "3353 -1.601648 -0.355809  0.949766  1.321265 -0.466270  0.004640  0.215675   \n",
       "3354 -0.368223 -0.230561 -0.612622  0.269717  0.421747  1.235381  0.532070   \n",
       "\n",
       "            20        21        22        23        24        25        26  \\\n",
       "0    -0.508829  0.590414 -0.746548 -0.419586  0.270346  0.159327 -0.097584   \n",
       "1     0.716241 -0.990446  0.508297 -0.129431  0.259507 -0.515533 -0.065383   \n",
       "2     1.087248 -0.627109  0.396787  0.138117 -0.195273 -0.538636  0.738193   \n",
       "3     0.198616 -0.624624 -0.060750  0.319459  0.765583 -0.513115  0.045952   \n",
       "4    -0.651149 -1.395147 -0.994150  0.009017 -0.860938 -0.113742  0.545029   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3350  0.296203  0.566254 -0.369008 -0.128690 -0.068601 -0.224132  0.179661   \n",
       "3351  0.485552  0.493027 -0.655081 -1.136077 -0.988839  0.346736 -0.365619   \n",
       "3352 -0.082800 -0.321606  0.940902  0.510068 -0.628191 -0.093034 -0.783109   \n",
       "3353 -0.126002 -0.929815  1.170759  0.055459 -0.362601  0.269442  0.277268   \n",
       "3354 -0.594915  0.423322  0.252245 -0.955708  0.562276 -0.073609  0.096507   \n",
       "\n",
       "            27        28        29        30        31        32        33  \\\n",
       "0     0.131015  0.327636  0.172926  0.269879  0.547658 -0.143616 -0.077515   \n",
       "1    -0.266527 -0.046385 -0.257940  0.103083 -0.291695 -0.314269 -0.067524   \n",
       "2     0.301050 -0.493639 -0.883594  0.137393 -0.190730  0.123261  0.202526   \n",
       "3     0.232231 -0.244286  0.224951 -0.061547  0.478726  0.181395 -0.377737   \n",
       "4    -0.164758 -0.668395 -0.389105  0.251451  0.914531  0.176540 -0.149310   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3350 -0.321636  0.291466 -0.189636 -0.446249  0.074973  0.111538  0.166842   \n",
       "3351  0.324004 -0.859652 -0.112508  0.557931 -0.157967  0.404897  0.333191   \n",
       "3352  0.015262  0.697227  0.389809  0.465626  0.231340 -0.343397  0.137666   \n",
       "3353  0.371096 -1.050715  1.144143  0.013688  0.202115 -0.213449 -0.289618   \n",
       "3354 -0.340302  0.637882  0.380862  0.196633 -0.345499  0.524958  0.384078   \n",
       "\n",
       "            34        35        36        37        38        39        40  \\\n",
       "0    -0.212644 -0.019858 -0.049473 -0.184009 -0.226855 -0.180927 -0.068320   \n",
       "1     0.405480  0.074450  0.368322 -0.033768 -0.304901 -0.022537 -0.112632   \n",
       "2     0.150256 -0.350714 -0.225407  0.392292  0.138637 -0.177242 -0.191377   \n",
       "3    -0.490816 -0.062465 -0.098364  0.088359  0.445133  0.150082  0.124207   \n",
       "4    -0.149043 -0.313318  0.048973 -0.584387  0.145278 -0.228382 -0.059748   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3350  0.192033 -0.452788 -0.068857  0.205273  0.272273 -0.102809 -0.067893   \n",
       "3351  0.189529 -0.287762 -0.177926 -0.305335 -0.089031  0.619654  0.231737   \n",
       "3352 -0.473930  0.552502  0.092304  0.438345  0.249907 -0.725016 -0.161702   \n",
       "3353 -0.108093  0.024667 -0.187419 -0.319528  0.043697  0.594970  0.128063   \n",
       "3354 -0.034621  0.054517  0.097114  0.014107 -0.082066 -0.060045  0.313545   \n",
       "\n",
       "            41        42        43        44  \n",
       "0     0.135709  0.032409 -0.055209  0.234126  \n",
       "1     0.130355  0.065607  0.137011  0.116226  \n",
       "2     0.230836  0.023830 -0.165797 -0.295334  \n",
       "3    -0.211369  0.006715  0.244105 -0.585212  \n",
       "4     0.237914 -0.277846  0.502227  0.132296  \n",
       "...        ...       ...       ...       ...  \n",
       "3350 -0.284417  0.143581 -0.110138 -0.052485  \n",
       "3351 -0.036520  0.325149  0.044162 -0.080211  \n",
       "3352  0.115188 -0.631952 -0.416700 -0.249932  \n",
       "3353 -0.160156 -0.144663 -0.203815  0.079255  \n",
       "3354  0.049815  0.094020  0.100053  0.032122  \n",
       "\n",
       "[3355 rows x 45 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns \t PearSon Coree \t\t pvalue \n",
      "\n",
      "0 \t 19.476964092350336 \t 4.8807611126883136e-30\n",
      "2 \t -7.230613378030369 \t 2.7642176841118125e-05\n",
      "3 \t -8.093504631001862 \t 2.680400243448609e-06\n",
      "6 \t 18.344086735611597 \t 8.903178944562297e-27\n",
      "7 \t -34.57372783727798 \t 8.127065386922516e-95\n",
      "9 \t 31.093069899407567 \t 4.1257682580382434e-76\n",
      "10 \t -11.316125304138032 \t 4.922949840070088e-11\n",
      "11 \t -29.87690151813034 \t 3.845361583790711e-70\n",
      "12 \t 11.941209221673187 \t 3.951839621596043e-12\n",
      "13 \t -16.01179736621214 \t 1.0466113111585193e-20\n",
      "14 \t 3.7531984695333658 \t 0.029712871826822224\n",
      "15 \t 14.895946630185728 \t 4.197813536968449e-18\n",
      "16 \t -33.094046662601805 \t 1.4521562854757674e-86\n",
      "17 \t 6.316568946996373 \t 0.00025123409159330355\n",
      "19 \t 3.94080895897767 \t 0.02245124745304944\n",
      "20 \t 6.755336060677536 \t 9.008040557945646e-05\n",
      "21 \t 6.286909987981766 \t 0.0002686687859802547\n",
      "22 \t 6.445252825099186 \t 0.00018716695916021252\n",
      "24 \t -3.9746810884929524 \t 0.021319331326801663\n",
      "25 \t 4.494765531211452 \t 0.00921911288482364\n",
      "32 \t -8.990460026596505 \t 1.8271799435588972e-07\n",
      "\n",
      " No of PCAs Highly Correlate with Target Veriable: ==>: 21 Outof_Available PCAs 45\n"
     ]
    }
   ],
   "source": [
    "columns = []\n",
    "print (\"columns\",\"\\t\", \"PearSon Coree\",\"\\t\\t\", \"pvalue\",\"\\n\")\n",
    "for col in X_train_pca_df.columns:\n",
    "    corre, pvalue = stats.pearsonr(X_train_pca_df[col], y_train)\n",
    "    \n",
    "    if (pvalue < 0.03):\n",
    "        print (col,\"\\t\", corre*100,\"\\t\", pvalue)\n",
    "        columns.append(col)\n",
    "print(\"\\n No of PCAs Highly Correlate with Target Veriable: ==>:\", len(columns), \"Outof_Available PCAs\",X_train_pca_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_df_final = X_train_pca_df[columns]\n",
    "X_test_pca_df_final = X_test_pca_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()\n",
    "\n",
    "for col in X_test_pca_df_final.columns:\n",
    "    X_train_pca_df_final[col] = mms.fit_transform(np.array(X_train_pca_df_final[col]).reshape(-1,1))\n",
    "    X_test_pca_df_final[col] = mms.transform(np.array(X_test_pca_df_final[col]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_Execute(xtrain, xtest, ytrain, ytest, model):\n",
    "    obj = model\n",
    "    obj.fit(xtrain, ytrain)\n",
    "    y_predict = obj.predict(xtest)\n",
    "    y_predict_train = obj.predict(xtrain)\n",
    "    \n",
    "    test_r2_score = r2_score(ytest, y_predict)\n",
    "    train_r2_score = r2_score(ytrain, y_predict_train)\n",
    "    print(str(obj).split(\"(\")[0])\n",
    "    print(\"Train Accuracy(R2 Score): ===========>\", train_r2_score)\n",
    "    print(\"Test Accuracuy(R2 Score): ===========>\", test_r2_score)\n",
    "    print(\"MeanSquareError: ====================>\", mean_squared_error(ytest, y_predict))\n",
    "    print(\"RootMeanSquareError: ================>\", np.sqrt(mean_squared_error(ytest, y_predict)), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'lr': LinearRegression(),\n",
    "    'dt': DecisionTreeRegressor(),\n",
    "    'rf': RandomForestRegressor(),\n",
    "    'agb': AdaBoostRegressor(),\n",
    "    'gbr': GradientBoostingRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "Train Accuracy(R2 Score): ===========> 0.6045571089259559\n",
      "Test Accuracuy(R2 Score): ===========> 0.6338208725002121\n",
      "MeanSquareError: ====================> 0.005346681039446841\n",
      "RootMeanSquareError: ================> 0.07312100272457182 \n",
      "\n",
      "DecisionTreeRegressor\n",
      "Train Accuracy(R2 Score): ===========> 0.977555485923921\n",
      "Test Accuracuy(R2 Score): ===========> 0.3428675759215123\n",
      "MeanSquareError: ====================> 0.009594969260579242\n",
      "RootMeanSquareError: ================> 0.09795391396253261 \n",
      "\n",
      "RandomForestRegressor\n",
      "Train Accuracy(R2 Score): ===========> 0.9225477583253731\n",
      "Test Accuracuy(R2 Score): ===========> 0.6069128682200342\n",
      "MeanSquareError: ====================> 0.005739572128779249\n",
      "RootMeanSquareError: ================> 0.07575996389108992 \n",
      "\n",
      "AdaBoostRegressor\n",
      "Train Accuracy(R2 Score): ===========> 0.39026222703366054\n",
      "Test Accuracuy(R2 Score): ===========> 0.3958639174572708\n",
      "MeanSquareError: ====================> 0.008821155263085752\n",
      "RootMeanSquareError: ================> 0.0939210054411991 \n",
      "\n",
      "GradientBoostingRegressor\n",
      "Train Accuracy(R2 Score): ===========> 0.6964456016918459\n",
      "Test Accuracuy(R2 Score): ===========> 0.6213794778206614\n",
      "MeanSquareError: ====================> 0.005528341227157751\n",
      "RootMeanSquareError: ================> 0.07435281586569369 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for mName, Model in models.items():\n",
    "    model_Execute(X_train_pca_df_final, X_test_pca_df_final, y_train, y_test, Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "adbR = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(), random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "adbR_params = {\n",
    "    'n_estimators': np.arange(5, 200, 5),\n",
    "    'learning_rate': np.linspace(0.0001, 1, 15),\n",
    "    'loss': ['linear', 'square', 'exponential'],\n",
    "    \"base_estimator__criterion\" : [\"friedman_mse\", \"mse\"],\n",
    "    \"base_estimator__min_samples_split\": np.arange(1, 20, 1),\n",
    "    \"base_estimator__min_samples_leaf\": np.arange(1, 20, 1),\n",
    "    \"base_estimator__max_depth\" : np.arange(1, 20, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsCV = RandomizedSearchCV(estimator=adbR, param_distributions=adbR_params, scoring='r2', n_jobs=-1, n_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score=nan,\n",
       "                   estimator=AdaBoostRegressor(base_estimator=DecisionTreeRegressor(ccp_alpha=0.0,\n",
       "                                                                                    criterion='mse',\n",
       "                                                                                    max_depth=None,\n",
       "                                                                                    max_features=None,\n",
       "                                                                                    max_leaf_nodes=None,\n",
       "                                                                                    min_impurity_decrease=0.0,\n",
       "                                                                                    min_impurity_split=None,\n",
       "                                                                                    min_samples_leaf=1,\n",
       "                                                                                    min_samples_split=2,\n",
       "                                                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                                                    presort='deprecated',\n",
       "                                                                                    random_state=None,\n",
       "                                                                                    sp...\n",
       "       8.57157143e-01, 9.28578571e-01, 1.00000000e+00]),\n",
       "                                        'loss': ['linear', 'square',\n",
       "                                                 'exponential'],\n",
       "                                        'n_estimators': array([  5,  10,  15,  20,  25,  30,  35,  40,  45,  50,  55,  60,  65,\n",
       "        70,  75,  80,  85,  90,  95, 100, 105, 110, 115, 120, 125, 130,\n",
       "       135, 140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190, 195])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='r2', verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsCV.fit(X_train_pca_df_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rsCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(ccp_alpha=0.0,\n",
       "                                                       criterion='mse',\n",
       "                                                       max_depth=11,\n",
       "                                                       max_features=None,\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=3,\n",
       "                                                       min_samples_split=14,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       presort='deprecated',\n",
       "                                                       random_state=None,\n",
       "                                                       splitter='best'),\n",
       "                  learning_rate=0.07152142857142857, loss='square',\n",
       "                  n_estimators=80, random_state=2020)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_pca_df_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor\n",
      "Train Accuracy(R2 Score): ===========> 0.8232381117775716\n",
      "Test Accuracuy(R2 Score): ===========> 0.6290172350027212\n",
      "MeanSquareError: ====================> 0.005416820257112178\n",
      "RootMeanSquareError: ================> 0.07359905065360679 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_Execute(X_train_pca_df_final, X_test_pca_df_final, y_train, y_test, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbR_hyp = GradientBoostingRegressor(random_state=42)\n",
    "gbr_params = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'loss': ['ls', 'lad', 'huber'],\n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': np.arange(1, 8),\n",
    "    'n_estimators': [5, 10, 15, 20],\n",
    "    'tol': [0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "score = make_scorer(r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_rsCV = RandomizedSearchCV(gbR_hyp, param_distributions=gbr_params, scoring=score, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score=nan,\n",
       "                   estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
       "                                                       criterion='friedman_mse',\n",
       "                                                       init=None,\n",
       "                                                       learning_rate=0.1,\n",
       "                                                       loss='ls', max_depth=3,\n",
       "                                                       max_features=None,\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=1,\n",
       "                                                       min_samples_split=2,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=100...\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'learning_rate': [0.001, 0.01, 0.1],\n",
       "                                        'loss': ['ls', 'lad', 'huber'],\n",
       "                                        'max_depth': [2, 3, 4, 5],\n",
       "                                        'min_samples_leaf': array([1, 2, 3, 4, 5, 6, 7]),\n",
       "                                        'n_estimators': [5, 10, 15, 20],\n",
       "                                        'tol': [0.0001, 0.001, 0.01, 0.1]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=make_scorer(r2_score),\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_rsCV.fit(X_train_pca_df_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_hyp_best = gbr_rsCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.1, loss='huber',\n",
       "                          max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=5, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=20,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=42, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_hyp_best.fit(X_train_pca_df_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor\n",
      "Train Accuracy(R2 Score): ===========> 0.5416350397706708\n",
      "Test Accuracuy(R2 Score): ===========> 0.5747885375689474\n",
      "MeanSquareError: ====================> 0.006208628218266997\n",
      "RootMeanSquareError: ================> 0.07879484893231915 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_Execute(X_train_pca_df_final, X_test_pca_df_final, y_train, y_test, gbr_hyp_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
